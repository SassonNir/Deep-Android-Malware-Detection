function testModel(allData, model)

	-- print('testing corrected verison 2')

	local timerTest = torch.Timer()

	local dtype = 'torch.DoubleTensor'
	if opt.useCUDA then
		dtype = 'torch.CudaTensor'
	end

	model:evaluate()
	predictions = {}
	for k = 1, allData.programStartPtrs:size(1) do

		local currProgramPtr = allData.programStartPtrs[k]
		local currProgramLen = allData.programLengths[k]
		local currProgramName = allData.programNames[k]

		if currProgramLen > opt.maxSequenceLength then
			currProgramLen = opt.maxSequenceLength
		end			

		local valBatch = torch.zeros(1,currProgramLen):type(dtype)
		valBatch[{{1},{}}] = allData.program[{{currProgramPtr, currProgramPtr + currProgramLen - 1}}]

		local netOutput = model:forward(valBatch)

		local netOutputProb = nn.Exp():forward(netOutput:double())

		local v,i = torch.max(netOutputProb,2)
		local pred = i[{1,1}]
		
		predictions[currProgramName] = pred
		
	end


	local time = timerTest:time().real	

	model:training()

	-- clean up
	collectgarbage()

	return time, predictions
end